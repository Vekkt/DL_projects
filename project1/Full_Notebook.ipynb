{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "extraordinary-nowhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlc_practical_prologue as prologue\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import statistics\n",
    "import numpy as np #Only used for visualisation of digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "provincial-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main network structure, plus training and compute errors functions\n",
    "\n",
    "class DigitNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(DigitNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, 5),\n",
    "            nn.BatchNorm2d(4),\n",
    "            #nn.Dropout2d(),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(4, 8, 3),\n",
    "            nn.BatchNorm2d(8),\n",
    "            #nn.Dropout2d(),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(8, 16, 3),\n",
    "            nn.BatchNorm2d(16),\n",
    "            #nn.Dropout2d(),\n",
    "            nn.PReLU()\n",
    "            )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(16 * 6 * 6, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            #nn.Dropout(),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            #nn.Dropout(),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(64, 10),\n",
    "            nn.Softmax(dim=1)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.features(x)\n",
    "        features = features.view(-1, 16 * 6 * 6)\n",
    "        digit = self.fc(features)\n",
    "        return digit\n",
    "    \n",
    "\n",
    "class PairSetsModel(nn.Module):\n",
    "\n",
    "    def __init__(self, weight_sharing = True, use_auxiliary_loss = True):\n",
    "        super(PairSetsModel, self).__init__()        \n",
    "        self.weight_sharing = weight_sharing\n",
    "        self.use_auxiliary_loss = use_auxiliary_loss        \n",
    "        self.net1 = DigitNet()\n",
    "        self.net2 = self.net1 if weight_sharing else DigitNet()        \n",
    "        self.fc = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, image1, image2):\n",
    "        digit1 = self.net1(image1)\n",
    "        digit2 = self.net2(image2)\n",
    "        digits = torch.bmm(digit1[:,:,None], digit2[:,None,:])\n",
    "        prediction = self.fc(digits.view(-1, 100)).view(-1)       \n",
    "        return prediction, digit1, digit2\n",
    "    \n",
    "\n",
    "def train_model(model, images1, images1_target, images2, images2_target,target, mini_batch_size, nb_epochs = 25):\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    criterion_aux = torch.nn.MSELoss()\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "    \n",
    "    for epoch in tqdm(range(nb_epochs)):    \n",
    "        # Train\n",
    "        epoch_loss = 0\n",
    "        epoch_accuracy = 0\n",
    "        for b in range(0, images1.size(0), mini_batch_size):\n",
    "            images1_here = images1.narrow(0,b,mini_batch_size)\n",
    "            images2_here = images2.narrow(0,b,mini_batch_size)\n",
    "            prediction, digit1, digit2 = model(images1_here, images2_here)\n",
    "            loss = criterion(prediction, target.narrow(0, b, mini_batch_size))\n",
    "            epoch_loss += loss\n",
    "            model.zero_grad()\n",
    "            if model.use_auxiliary_loss: \n",
    "                    aux_loss = criterion_aux(digit1, images1_target.narrow(0,b,mini_batch_size)) \n",
    "                    aux_loss += criterion_aux(digit2, images2_target.narrow(0,b,mini_batch_size))\n",
    "                    loss += aux_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print('epochs = ', epoch, ', loss = ', epoch_loss)\n",
    "\n",
    "def compute_nb_errors(model, images1, images2, target, mini_batch_size):\n",
    "    nb_errors = 0\n",
    "\n",
    "    for b in range(0, images1.size(0), mini_batch_size):\n",
    "        images1_here = images1.narrow(0,b,mini_batch_size)\n",
    "        images2_here = images2.narrow(0,b,mini_batch_size)\n",
    "        prediction, digit1, digit2 = model(images1_here, images2_here)\n",
    "        predicted_target = torch.empty(prediction.size())\n",
    "        for k in range(mini_batch_size):\n",
    "            predicted_target[k] = 0.0 if prediction[k]< 0.5 else 1.0\n",
    "            if target[b + k] != predicted_target[k]:\n",
    "                nb_errors = nb_errors + 1\n",
    "    return nb_errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "secondary-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data acquisition\n",
    "N = 1000\n",
    "get1 = prologue.generate_pair_sets(N)\n",
    "# get1 will be a tuple of size 6: \n",
    "#      position 0 has a Nx2x14x14 torch containing train images\n",
    "#      position 1 has a N torch containing train target [0 or 1]\n",
    "#      position 2 has a Nx2 torch containing train classes [0,...,9]x[0,...,9]\n",
    "#      position 3 has a Nx2x14x14 torch containing test images\n",
    "#      position 4 has a N torch containing test target [0 or 1]\n",
    "#      position 5 has a Nx2 torch containing test classes [0,...,9]x[0,...,9]\n",
    "\n",
    "# Extract data from get1\n",
    "train_images1 = get1[0][:,0,:, :].to(torch.float32)\n",
    "train_images2 = get1[0][:,1,:, :].to(torch.float32)\n",
    "train_classes_images1 = get1[2][:,0].to(torch.float32)\n",
    "train_classes_images2 = get1[2][:,1].to(torch.float32)\n",
    "train_target = get1[1].to(torch.float32)\n",
    "\n",
    "test_images1 = get1[3][:,0,:, :].to(torch.float32)\n",
    "test_images2 = get1[3][:,1,:, :].to(torch.float32)\n",
    "test_classes_images1 = get1[5][:,0].to(torch.float32)\n",
    "test_classes_images2 = get1[5][:,1].to(torch.float32)\n",
    "test_target = get1[4].to(torch.float32)\n",
    "\n",
    "train_classes_long_images1 = torch.zeros((train_classes_images1.size()[0], 10))\n",
    "train_classes_long_images2 = torch.zeros((train_classes_images2.size()[0], 10))\n",
    "\n",
    "test_classes_long_images1 = torch.zeros((test_classes_images1.size()[0], 10))\n",
    "test_classes_long_images2 = torch.zeros((test_classes_images2.size()[0], 10))\n",
    "\n",
    "\n",
    "for k in range(N):\n",
    "    train_classes_long_images1[k, train_classes_images1[k].to(torch.int) ] = 1.0\n",
    "    train_classes_long_images2[k, train_classes_images2[k].to(torch.int) ] = 1.0\n",
    "    \n",
    "    test_classes_long_images1[k, test_classes_images1[k].to(torch.int) ] = 1.0\n",
    "    test_classes_long_images2[k, test_classes_images2[k].to(torch.int) ] = 1.0\n",
    "\n",
    "# My version of pytorch makes me do this for the network to read inputs correctly    \n",
    "train_images1 = train_images1.view(1000, -1, 14, 14)\n",
    "train_images2 = train_images2.view(1000, -1, 14, 14)\n",
    "\n",
    "test_images1 = test_images1.view(1000, -1, 14, 14)\n",
    "test_images2 = test_images2.view(1000, -1, 14, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "persistent-strategy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [00:00<00:10,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , loss =  tensor(6.5938, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 2/25 [00:00<00:10,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  1 , loss =  tensor(3.7033, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 3/25 [00:01<00:09,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  2 , loss =  tensor(2.2273, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 4/25 [00:01<00:09,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  3 , loss =  tensor(1.2765, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 5/25 [00:02<00:08,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  4 , loss =  tensor(0.8430, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 6/25 [00:02<00:08,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  5 , loss =  tensor(0.6086, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 7/25 [00:03<00:08,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  6 , loss =  tensor(0.3842, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 8/25 [00:03<00:07,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  7 , loss =  tensor(0.4161, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 9/25 [00:03<00:07,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  8 , loss =  tensor(0.2101, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 10/25 [00:04<00:06,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  9 , loss =  tensor(0.2109, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 11/25 [00:04<00:06,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  10 , loss =  tensor(0.1377, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 12/25 [00:05<00:05,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  11 , loss =  tensor(0.1117, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 13/25 [00:05<00:05,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  12 , loss =  tensor(0.0956, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 14/25 [00:06<00:05,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  13 , loss =  tensor(0.0151, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 15/25 [00:06<00:04,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  14 , loss =  tensor(0.0051, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 16/25 [00:07<00:04,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  15 , loss =  tensor(0.0023, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 17/25 [00:07<00:04,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  16 , loss =  tensor(0.0008, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 18/25 [00:08<00:03,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  17 , loss =  tensor(0.0005, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 19/25 [00:09<00:03,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  18 , loss =  tensor(0.0003, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 20/25 [00:09<00:02,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  19 , loss =  tensor(0.0002, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 21/25 [00:09<00:01,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  20 , loss =  tensor(0.0002, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 22/25 [00:10<00:01,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  21 , loss =  tensor(0.0001, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 23/25 [00:10<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  22 , loss =  tensor(8.1940e-05, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 24/25 [00:11<00:00,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  23 , loss =  tensor(6.5952e-05, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:11<00:00,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  24 , loss =  tensor(6.0015e-05, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error Net 0.00% 0/1000\n",
      "Test error Net 3.30% 33/1000\n"
     ]
    }
   ],
   "source": [
    "# MAIN\n",
    "model = PairSetsModel(weight_sharing=True, use_auxiliary_loss=True)\n",
    "mini_batch_size = 50\n",
    "nb_epochs = 25\n",
    "train_model(model, train_images1, train_classes_long_images1, train_images2, train_classes_long_images2,\n",
    "            train_target, mini_batch_size, nb_epochs)\n",
    "\n",
    "## Train&Test Errors:\n",
    "nb_train_errors = compute_nb_errors(model, train_images1, train_images2, train_target, mini_batch_size)\n",
    "print('Train error Net {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_images1.size(0),\n",
    "                                                nb_train_errors, train_images1.size(0)))\n",
    "\n",
    "nb_test_errors = compute_nb_errors(model, test_images1, test_images2, test_target, mini_batch_size)\n",
    "print('Test error Net {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / train_images2.size(0),\n",
    "                                                nb_test_errors, test_images1.size(0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "personal-study",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target =  1.0 Predicted =  1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Run this to plot some examples\n",
    "j = 1 # Change this from 0 to 999 to visualize a few examples\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "prediction, digit1, digit2 = model(train_images1, train_images2)\n",
    "for k in range(prediction.size()[0]):\n",
    "    prediction[k] = 0.0 if prediction[k]<0.5 else 1.0\n",
    "first_digit = train_images1[j]\n",
    "_, first_digit_predicted = digit1.max(-1)\n",
    "second_digit = train_images2[j]\n",
    "_, second_digit_predicted = digit2.max(-1)\n",
    "target = train_target[j]\n",
    "label_image1 = str(int(train_classes_images1[j].item()))\n",
    "label_image2 = str(int(train_classes_images2[j].item()))\n",
    "\n",
    "print('Target = ', target.item(), 'Predicted = ', prediction[j].item())\n",
    "first_digit = np.array(first_digit, dtype='float')\n",
    "second_digit = np.array(second_digit, dtype='float')\n",
    "pixels = first_digit.reshape((14, 14))\n",
    "ax1 = fig.add_subplot(2,2,1)\n",
    "ax1.imshow(pixels, cmap='gray')\n",
    "plt.title('First: (Pred, Real ) = ('+ str(first_digit_predicted[j].item()) + ','+ label_image1+')')\n",
    "pixels2 = second_digit.reshape((14, 14))\n",
    "ax2 = fig.add_subplot(2,2,2)\n",
    "ax2.imshow(pixels2, cmap='gray')\n",
    "plt.title('Second: (Pred, Real ) = ('+ str(second_digit_predicted[j].item()) + ','+ label_image2+')')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-pixel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
